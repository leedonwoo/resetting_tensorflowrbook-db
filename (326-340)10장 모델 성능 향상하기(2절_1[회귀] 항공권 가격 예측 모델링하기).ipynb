{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2032738e-0e1e-48b6-8108-24cac080bf36",
   "metadata": {},
   "source": [
    "# 2절. 머신러닝 모델링 및 하이퍼파라미터 튜닝 실습하기\n",
    "항공권 가격 예측 데이터 세트와 항공사 고객 만족 여부 데이터 세트를 가지고 머신러닝 모델을 학습한 다음, 하이퍼파라미터 튜닝 실습을 통해 성능을 개선해 봅니다. 데이터는 항공권 가격 예측 데이터에 있는 clean_Dataset.csv를 사용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a11fe60-da35-4fc9-a24d-5e36c005a659",
   "metadata": {},
   "source": [
    "## 1. [회귀] 항공권 가격 예측 모델링하기\n",
    "금액을 예측하는 과제이므로 회귀 분석에 포함됩니다. 회귀 모델을 만들기 위해 데이터를 확인합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794683e8-6f11-4f09-a08e-e961dbc2d769",
   "metadata": {},
   "source": [
    "<div style=\"display:table; border-collapse:collapse; width:100%; text-align:center;\">\n",
    "\t<div style=\"display:table-row; background-color:#d9e2f3; font-weight:bold\">\n",
    "\t\t<div style=\"display:table-cell; border:1px solid black; padding:5px;\">칼럼명</div>\n",
    "\t\t<div style=\"display:table-cell; border:1px solid black; padding:5px;\">설명</div>\n",
    "        <div style=\"display:table-cell; border:1px solid black; padding:5px;\">칼럼명</div>\n",
    "        <div style=\"display:table-cell; border:1px solid black; padding:5px;\">설명</div>\n",
    "\t</div>\n",
    "\t<div style=\"display:table-row;\">\n",
    "\t\t<div style=\"display:table-cell; border:1px solid black; padding:5px;\">Airline</div>\n",
    "\t\t<div style=\"display:table-cell; border:1px solid black; padding:5px;\">항공사 이름</div>\n",
    "\t\t<div style=\"display:table-cell; border:1px solid black; padding:5px;\">Destination City</div>\n",
    "\t\t<div style=\"display:table-cell; border:1px solid black; padding:5px;\">도착 도시</div>\n",
    "\t</div>\n",
    "\t<div style=\"display:table-row;\">\n",
    "\t\t<div style=\"display:table-cell; border:1px solid black; padding:5px;\">Flight</div>\n",
    "\t\t<div style=\"display:table-cell; border:1px solid black; padding:5px;\">항공편명</div>\n",
    "\t\t<div style=\"display:table-cell; border:1px solid black; padding:5px;\">Class</div>\n",
    "\t\t<div style=\"display:table-cell; border:1px solid black; padding:5px;\">좌석 등급</div>\n",
    "\t</div>\n",
    "\t<div style=\"display:table-row;\">\n",
    "\t\t<div style=\"display:table-cell; border:1px solid black; padding:5px;\">Source City</div>\n",
    "\t\t<div style=\"display:table-cell; border:1px solid black; padding:5px;\">출발 도시</div>\n",
    "\t\t<div style=\"display:table-cell; border:1px solid black; padding:5px;\">Duration</div>\n",
    "\t\t<div style=\"display:table-cell; border:1px solid black; padding:5px;\">비행시간</div>\n",
    "\t</div>\n",
    "\t<div style=\"display:table-row;\">\n",
    "\t\t<div style=\"display:table-cell; border:1px solid black; padding:5px;\">Departure Time</div>\n",
    "\t\t<div style=\"display:table-cell; border:1px solid black; padding:5px;\">출발 시간</div>\n",
    "\t\t<div style=\"display:table-cell; border:1px solid black; padding:5px;\">Days Left</div>\n",
    "\t\t<div style=\"display:table-cell; border:1px solid black; padding:5px;\">출발까지 남은 일자</div>\n",
    "\t</div>\n",
    "\t<div style=\"display:table-row;\">\n",
    "\t\t<div style=\"display:table-cell; border:1px solid black; padding:5px;\">Stops</div>\n",
    "\t\t<div style=\"display:table-cell; border:1px solid black; padding:5px;\">환승장 수</div>\n",
    "\t\t<div style=\"display:table-cell; border:1px solid black; padding:5px;\">Price</div>\n",
    "\t\t<div style=\"display:table-cell; border:1px solid black; padding:5px;\">항공권 가격</div>\n",
    "\t</div>\n",
    "\t<div style=\"display:table-row;\">\n",
    "\t\t<div style=\"display:table-cell; border:1px solid black; padding:5px;\">Arrival Time</div>\n",
    "\t\t<div style=\"display:table-cell; border:1px solid black; padding:5px;\">도착 시간</div>\n",
    "\t\t<div style=\"display:table-cell; border:1px solid black; padding:5px;\"></div>\n",
    "\t\t<div style=\"display:table-cell; border:1px solid black; padding:5px;\"></div>\n",
    "\t</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14546a9-02a2-4c3f-b5f3-7fe62d4b3e2e",
   "metadata": {},
   "source": [
    "### 1) 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dcc12b3b-dd53-42e9-8614-faf8c91e40e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>airline</th>\n",
       "      <th>flight</th>\n",
       "      <th>source_city</th>\n",
       "      <th>departure_time</th>\n",
       "      <th>stops</th>\n",
       "      <th>arrival_time</th>\n",
       "      <th>destination_city</th>\n",
       "      <th>class</th>\n",
       "      <th>duration</th>\n",
       "      <th>days_left</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>SpiceJet</td>\n",
       "      <td>SG-8709</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Evening</td>\n",
       "      <td>zero</td>\n",
       "      <td>Night</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Economy</td>\n",
       "      <td>2.17</td>\n",
       "      <td>1</td>\n",
       "      <td>5953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   airline   flight source_city departure_time stops  \\\n",
       "0           0  SpiceJet  SG-8709       Delhi        Evening  zero   \n",
       "\n",
       "  arrival_time destination_city    class  duration  days_left  price  \n",
       "0        Night           Mumbai  Economy      2.17          1   5953  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 판다스 라이브러리 불러오기\n",
    "import pandas as pd\n",
    "cdf = pd.read_csv(\"Clean_Dataset.csv\")\n",
    "\n",
    "# 학습시간 단축을 위해 5000건만 추출하기\n",
    "cdf = cdf[:5000]\n",
    "\n",
    "# 데이터 확인하기\n",
    "cdf.head(1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617bc020-08ff-4342-abda-15957898115f",
   "metadata": {},
   "source": [
    "데이터를 읽었을 때 Unnamed: 0이라는 칼럼 데이터를 볼 수 있습니다. 데이터세트를 처음 저장했을 때 index를 같이 저장하여 생긴 칼럼으로 모델 학습에 불필요하니 삭제합니다. \n",
    "\n",
    "### 2) 데이터 전처리하기\n",
    "#### (1) Unnamed 삭제 및 데이터 기초 통계 정보 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c87cb982-4d88-4c8c-8a6e-d5a8f538f1f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0\n",
       "0       1\n",
       "3330    1\n",
       "3337    1\n",
       "3336    1\n",
       "3335    1\n",
       "       ..\n",
       "1666    1\n",
       "1665    1\n",
       "1664    1\n",
       "1663    1\n",
       "4999    1\n",
       "Name: count, Length: 5000, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unnamed: 0 데이터 분포 확인하기\n",
    "cdf[\"Unnamed: 0\"].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a188b403-f810-40ad-b043-1b26635ca650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unnamed 컬럼 삭제하기\n",
    "cdf.drop(\"Unnamed: 0\", axis = 1, inplace =True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73fae22-fd7d-4274-859b-88dc39cc0bd2",
   "metadata": {},
   "source": [
    "각 칼럼별 기초 통계 정보를 확인합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ffef550-9c37-4041-9e08-dbcd78d60581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline</th>\n",
       "      <th>flight</th>\n",
       "      <th>source_city</th>\n",
       "      <th>departure_time</th>\n",
       "      <th>stops</th>\n",
       "      <th>arrival_time</th>\n",
       "      <th>destination_city</th>\n",
       "      <th>class</th>\n",
       "      <th>duration</th>\n",
       "      <th>days_left</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>6</td>\n",
       "      <td>222</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Vistara</td>\n",
       "      <td>UK-819</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Evening</td>\n",
       "      <td>one</td>\n",
       "      <td>Night</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Economy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1496</td>\n",
       "      <td>90</td>\n",
       "      <td>5000</td>\n",
       "      <td>1391</td>\n",
       "      <td>3619</td>\n",
       "      <td>1702</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.665682</td>\n",
       "      <td>14.216800</td>\n",
       "      <td>7589.786600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.247512</td>\n",
       "      <td>7.109536</td>\n",
       "      <td>4476.362204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2409.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.330000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4678.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.670000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>5955.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.080000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>10549.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.080000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>31260.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        airline  flight source_city departure_time stops arrival_time  \\\n",
       "count      5000    5000        5000           5000  5000         5000   \n",
       "unique        6     222           1              6     3            6   \n",
       "top     Vistara  UK-819       Delhi        Evening   one        Night   \n",
       "freq       1496      90        5000           1391  3619         1702   \n",
       "mean        NaN     NaN         NaN            NaN   NaN          NaN   \n",
       "std         NaN     NaN         NaN            NaN   NaN          NaN   \n",
       "min         NaN     NaN         NaN            NaN   NaN          NaN   \n",
       "25%         NaN     NaN         NaN            NaN   NaN          NaN   \n",
       "50%         NaN     NaN         NaN            NaN   NaN          NaN   \n",
       "75%         NaN     NaN         NaN            NaN   NaN          NaN   \n",
       "max         NaN     NaN         NaN            NaN   NaN          NaN   \n",
       "\n",
       "       destination_city    class     duration    days_left         price  \n",
       "count              5000     5000  5000.000000  5000.000000   5000.000000  \n",
       "unique                1        1          NaN          NaN           NaN  \n",
       "top              Mumbai  Economy          NaN          NaN           NaN  \n",
       "freq               5000     5000          NaN          NaN           NaN  \n",
       "mean                NaN      NaN     9.665682    14.216800   7589.786600  \n",
       "std                 NaN      NaN     7.247512     7.109536   4476.362204  \n",
       "min                 NaN      NaN     2.000000     1.000000   2409.000000  \n",
       "25%                 NaN      NaN     2.330000     8.000000   4678.000000  \n",
       "50%                 NaN      NaN     7.670000    14.000000   5955.000000  \n",
       "75%                 NaN      NaN    14.080000    20.000000  10549.000000  \n",
       "max                 NaN      NaN    30.080000    26.000000  31260.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # 기초 통계정보 확인하기\n",
    "cdf.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcae8889-8040-4d88-82cb-a5e184def1df",
   "metadata": {},
   "source": [
    "8개의 문자형 칼럼에 대한 정보와 3개의 수치형 칼럼에 대한 정보를 확인할 수 있습니다. "
   ]
  },
  {
   "cell_type": "raw",
   "id": "e118d6ca-f887-454f-a4b9-2588d538821c",
   "metadata": {},
   "source": [
    "#329"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c88600a-60f8-4391-8f81-357e083340f3",
   "metadata": {},
   "source": [
    "#### (2) Null 데이터 분석 및 처리하기\n",
    "기본적인 정보는 확인했으니 Null 데이터가 없는지 확인합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf18f9fa-6203-47b9-a080-8347581d06a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null 데이터 확인\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 11 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   airline           5000 non-null   object \n",
      " 1   flight            5000 non-null   object \n",
      " 2   source_city       5000 non-null   object \n",
      " 3   departure_time    5000 non-null   object \n",
      " 4   stops             5000 non-null   object \n",
      " 5   arrival_time      5000 non-null   object \n",
      " 6   destination_city  5000 non-null   object \n",
      " 7   class             5000 non-null   object \n",
      " 8   duration          5000 non-null   float64\n",
      " 9   days_left         5000 non-null   int64  \n",
      " 10  price             5000 non-null   int64  \n",
      "dtypes: float64(1), int64(2), object(8)\n",
      "memory usage: 429.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# info를 통해 Null 데이터 및 type 확인 있는지 1차 확인하기(isna를 사용해도 됨)\n",
    "print(\"Null 데이터 확인\")\n",
    "cdf.info() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd2b866-296c-416d-b4a5-e233e2dcd4a4",
   "metadata": {},
   "source": [
    "info로 확인한 결과 모든 데이터의 non-null 개수가 동일한 것으로 보아 Null 데이터가 없는 것을 알 수 있습니다. \n",
    "\n",
    "#### (3) airline 칼럼 분석 및 처리하기\n",
    "이번 장에서는 하이퍼파라미터 튜닝을 위해 간단히 전처리만 할 예정이므로 airline과 flight 정보가 머신러닝 데이터로서 유의미한지 살펴봅니다.<br>\n",
    "우선 airline(항공사) 칼럼이 어떤 분포를 통해 구성되어 있는지 확인합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e061438c-d5d8-46bb-ac2a-02a19b52cc99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "airline\n",
       "Vistara      1496\n",
       "Air_India    1311\n",
       "Indigo        813\n",
       "GO_FIRST      801\n",
       "SpiceJet      296\n",
       "AirAsia       283\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 첫 번째 컬럼이 의미있는 컬럼인지 확인하기 위해 value_count로 분포 확인하기\n",
    "cdf.airline.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa18b90a-28e1-4fd6-a993-f212ea1be916",
   "metadata": {},
   "source": [
    "value_counts 메소드를 통해 분포를 확인하면 총 6개 항공사가 보입니다. 항공사의 수가 몇 개 되지 않기에 가격과 연관성이 있는지 그래프를 통해 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a646fb7d-67d9-4911-8a63-0695019ddbaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 그래프 라이브러리 불러오기(matplotlib, seaborn)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Seaborn 으로 막대그래프 그리기\n",
    "# 배경 사이즈 설정하기\n",
    "plt.figure(figsize=(5,5))\n",
    "# 막대그래프 차트 그리기 \n",
    "ax = sns.barplot(x='airline', y='price', data=cdf)\n",
    "# 상단 타이틀 지정하기\n",
    "ax.set(title='airline & price')\n",
    "# 그래프 출력하기\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f2e8c4-1428-42fb-80b7-fa4d1a4ae504",
   "metadata": {},
   "source": [
    "그래프를 보면 비스타라(Vistara) 항공사와 에어인디아(Air_India) 항공사의 가격이 높은 것을 확인할 수 있습니다. 항공사별로 가격에 영향을 주는 것처럼 보이니 일단 airline 칼럼은 유지합니다. \n",
    "\n",
    "\n",
    "#### (4) flight 칼럼 분석 및 처리하기\n",
    "flight 칼럼을 분석해 봅니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ccd95b3f-d2b2-47d2-9017-230f94078464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "flight\n",
       "UK-819     90\n",
       "UK-879     62\n",
       "UK-899     61\n",
       "UK-705     61\n",
       "UK-835     60\n",
       "           ..\n",
       "AI-9939     2\n",
       "I5-881      2\n",
       "I5-744      1\n",
       "SG-9974     1\n",
       "SG-8339     1\n",
       "Name: count, Length: 222, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2번째 flight 값 재확인하기\n",
    "cdf.head(1)\n",
    "\n",
    "# flight column 분포 확인하기\n",
    "cdf.flight.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007bcc00-f4b9-4c32-b48f-b7cf82b20038",
   "metadata": {},
   "source": [
    "데이터에서 보듯이 flight는 항공편명입니다. 항공편명은 222개의 유일값(unique) 데이터가 존재하고 데이터의 분포도 어느 정도 있어 보입니다. <br>\n",
    "이번에는 추가 분석보다 항공편명의 의미를 확인하고 전처리 및 삭제 진행 유무를 정해 봅니다. 국적 항공사에서 제공한 정보를 토대로 항공편명이 머신러닝 데이터로서 가치 있는지를 확인합니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbb21a8-2051-498d-967a-19c5c8c1b803",
   "metadata": {},
   "source": [
    "**1. 3자리 코드와 4자리 코드는 유의미한 데이터인가?**\n",
    "<div style=\"display:table; border-collapse:collapse; width:100%; text-align:center;\">\n",
    "\t<div style=\"display:table-row; background-color:#d9e2f3; font-weight:bold\">\n",
    "\t\t<div style=\"display:table-cell; border:1px solid black; padding:5px;\">항공편명</div>\n",
    "\t\t<div style=\"display:table-cell; border:1px solid black; padding:5px;\">의미</div>\n",
    "\t</div>\n",
    "\t<div style=\"display:table-row;\">\n",
    "\t\t<div style=\"display:table-cell; border:1px solid black; padding:5px;\">3자리 코드</div>\n",
    "\t\t<div style=\"display:table-cell; border:1px solid black; padding:5px;\">국제선</div>\n",
    "\t</div>\n",
    "\t<div style=\"display:table-row;\">\n",
    "\t\t<div style=\"display:table-cell; border:1px solid black; padding:5px;\">4자리 코드</div>\n",
    "\t\t<div style=\"display:table-cell; border:1px solid black; padding:5px;\">국내선</div>\n",
    "\t</div>\n",
    "</div>\n",
    "▲ 비행 코드의 의미 <p>\n",
    "\n",
    "**2. 코드의 패턴은 유의미한가?**\n",
    "<div style=\"display:table; border-collapse:collapse; width:100%; text-align:center;\">\n",
    "\t<div style=\"display:table-row; background-color:#d9e2f3; font-weight:bold\">\n",
    "\t\t<div style=\"display:table-cell; border:1px solid black; padding:5px;\">사업/지역(대한항공 기준)</div>\n",
    "\t\t<div style=\"display:table-cell; border:1px solid black; padding:5px;\">대한항공 코드</div>\n",
    "        <div style=\"display:table-cell; border:1px solid black; padding:5px;\">아시아나 코드</div>\n",
    "\t</div>\n",
    "\t<div style=\"display:table-row;\">\n",
    "\t\t<div style=\"display:table-cell; border:1px solid black; padding:5px;\">미주</div>\n",
    "\t\t<div style=\"display:table-cell; border:1px solid black; padding:5px;\">001~099</div>\n",
    "\t\t<div style=\"display:table-cell; border:1px solid black; padding:5px;\">600~699</div>\n",
    "\t</div>\n",
    "\t<div style=\"display:table-row;\">\n",
    "\t\t<div style=\"display:table-cell; border:1px solid black; padding:5px;\">대양주 및 괌</div>\n",
    "\t\t<div style=\"display:table-cell; border:1px solid black; padding:5px;\">100~149</div>\n",
    "\t\t<div style=\"display:table-cell; border:1px solid black; padding:5px;\">600~699</div>\n",
    "\t</div>\n",
    "\t<div style=\"display:table-row;\">\n",
    "\t\t<div style=\"display:table-cell; border:1px solid black; padding:5px;\">중국(몽골 포함)</div>\n",
    "\t\t<div style=\"display:table-cell; border:1px solid black; padding:5px;\">150~199<br>800~899</div>\n",
    "\t\t<div style=\"display:table-cell; border:1px solid black; padding:5px;\">300~399(중국만)</div>\n",
    "\t</div>\n",
    "\t<div style=\"display:table-row;\">\n",
    "\t\t<div style=\"display:table-cell; border:1px solid black; padding:5px;\">동남아, 홍콩, 대만</div>\n",
    "\t\t<div style=\"display:table-cell; border:1px solid black; padding:5px;\">460~499<br>600~699</div>\n",
    "\t\t<div style=\"display:table-cell; border:1px solid black; padding:5px;\">700~799</div>\n",
    "\t</div>\n",
    "\t<div style=\"display:table-row;\">\n",
    "\t\t<div style=\"display:table-cell; border:1px solid black; padding:5px;\">일본</div>\n",
    "\t\t<div style=\"display:table-cell; border:1px solid black; padding:5px;\">700~799</div>\n",
    "\t\t<div style=\"display:table-cell; border:1px solid black; padding:5px;\">001~099</div>\n",
    "\t</div>\n",
    "\t<div style=\"display:table-row;\">\n",
    "\t\t<div style=\"display:table-cell; border:1px solid black; padding:5px;\">유럽</div>\n",
    "\t\t<div style=\"display:table-cell; border:1px solid black; padding:5px;\">900~999</div>\n",
    "\t\t<div style=\"display:table-cell; border:1px solid black; padding:5px;\">500~599(몽골 포함)</div>\n",
    "\t</div>\n",
    "</div>\n",
    "▲ 항공편명 패턴 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0645864-b10a-4a03-8688-0c5204038e64",
   "metadata": {},
   "source": [
    "항공편명이 충분히 유의미한 것으로 보입니다. 다만 데이터 내에 ‘출발지, 도착지, 거리’ 등이 있어 대체 가능한 것으로 보입니다. 따라서 fight 칼럼은 삭제하는 것으로 전처리합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "857f328b-c56a-482c-aef4-7b9cbc3ccf79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 10)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# flight 칼럼은 다른 칼럼과 의미가 중복되는 것으로 보이므로 삭제하기\n",
    "cdf.drop('flight', axis=1, inplace=True)\n",
    "# 잘 삭제되었는지 shape 확인하기\n",
    "cdf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d94c2b-0bc3-420a-ae5c-e600af8a8cb0",
   "metadata": {},
   "source": [
    "2가지 데이터의 기본 분석만을 바탕으로 어떤 모델이 좋은 성능을 발휘하는지 데이터를 모델에 적용하여 확인합니다. \n",
    "\n",
    "\n",
    "#### (5) 원핫 인코딩하기\n",
    "먼저 모델 적용을 위한 필수 항목인 범주형 데이터의 수치화를 진행합니다. 데이터를 다시 확인해보면 문자형(object) 변수 중에 실제로는 숫자로 된 수치값인데 문자형으로 지정되어 있거나, 수치형(float64, int64) 변수 중 실제로는 범주형이지만 수치형으로 지정되어 있는 것은 없습니다. info정보에서 확인한 전체 문자형(object) 변수에 대해 원핫 인코딩을 적용합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7fccf6ae-1af8-4075-825b-25f8b6d65d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원핫인코딩 전 (5000, 10)\n",
      "원핫인코딩 후 (5000, 20)\n"
     ]
    }
   ],
   "source": [
    "# one_hot 인코딩을 위해 get_dummies 처리하기\n",
    "dummies_cdf = pd.get_dummies(cdf, \n",
    "               columns=[\"airline\", 'source_city','departure_time', 'stops','arrival_time', 'destination_city', 'class'],\n",
    "               drop_first=True\n",
    "              )\n",
    "\n",
    "# 인코딩 확인하기\n",
    "print(f'''원핫인코딩 전 {cdf.shape}\n",
    "원핫인코딩 후 {dummies_cdf.shape}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d118ec61-2045-4723-9ae6-70b08a023e29",
   "metadata": {},
   "source": [
    "#### (6) 학습 데이터 만들기\n",
    "인코딩이 완료된 데이터를 x(입력변수)와 y(타깃 변수) 데이터로 분리합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "93e36397-f751-4da5-bd89-edb423a451e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5953\n",
       "1    5953\n",
       "2    5956\n",
       "3    5955\n",
       "4    5955\n",
       "Name: price, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터프레임에서 타깃 변수만 y로 추출하기\n",
    "y = dummies_cdf.price\n",
    "\n",
    "# y 값의 형태 확인하기\n",
    "y.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926a2f93-6b05-4082-b9aa-900adb43962c",
   "metadata": {},
   "source": [
    "실행 결과를 보면 우리가 활용해야 할 타깃 변수만을 정상적으로 분리한 것을 확인할 수 있습니다. 다음은 데이터프레임에서 타깃 변수를 제외한 입력 데이터세트를 만들어 봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9155d114-0a0e-4a3d-b1b6-a44f4f205c4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000, 19), (5000,))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터프레임에서 타깃 변수를 제외한 입력 데이터세트를 생성하기\n",
    "x = dummies_cdf.drop('price', axis=1)\n",
    "\n",
    "x.head(5)\n",
    "\n",
    "# shape 확인하기\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821eee6b-fa5c-4952-9a18-fa05c138ddfa",
   "metadata": {},
   "source": [
    "실행 결과 타깃 변수인 price가 제거된 학습 데이터만 남아 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5eea2f-a32c-42af-b0e0-23f52aa827df",
   "metadata": {},
   "source": [
    "### 3) 모델 학습하기\n",
    "학습 데이터와 라벨 데이터가 갖춰졌으니 이제 머신러닝 모델 작업을 진행합니다. 사이킷런 기반의 모델들을 불러오고, 앙상블 계열 모델을 몇 개 더 추가하여 성능을 비교해 봅니다. \n",
    "\n",
    "#### (1) 머신러닝 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e19ebf6-a0ec-4af9-bcc5-32da2ef4c120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Using cached xgboost-2.1.2-py3-none-win_amd64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\ubion\\anaconda3\\envs\\aitensor\\lib\\site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\ubion\\anaconda3\\envs\\aitensor\\lib\\site-packages (from xgboost) (1.13.1)\n",
      "Using cached xgboost-2.1.2-py3-none-win_amd64.whl (124.9 MB)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-2.1.2\n",
      "Collecting lightgbm\n",
      "  Using cached lightgbm-4.5.0-py3-none-win_amd64.whl.metadata (17 kB)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\ubion\\anaconda3\\envs\\aitensor\\lib\\site-packages (from lightgbm) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\ubion\\anaconda3\\envs\\aitensor\\lib\\site-packages (from lightgbm) (1.13.1)\n",
      "Using cached lightgbm-4.5.0-py3-none-win_amd64.whl (1.4 MB)\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-4.5.0\n"
     ]
    }
   ],
   "source": [
    "# # xgboost, lightgbm모델 설치하기\n",
    "# !pip install xgboost\n",
    "# !pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "324e3ed7-6ae6-46a7-84b0-91d904ae8ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scikit learn 기반 라이브러리 불러오기\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "# scikit learn 외 라이브러리 불러오기\n",
    "from xgboost import XGBRFRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "# 학습_검증 데이터 분리 라이브러리 불러오기\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51107345-4041-43a4-8209-7082ca3922c7",
   "metadata": {},
   "source": [
    "사이킷런의 5개 모델(LinearRegression, DecisionTree, RandomForest, GradientBoosting, ExtraTrees)과 외부 모델 2가지(xgboost, lightgbm)를 더해 총 7가지 모델로 학습을 진행합니다. \n",
    "\n",
    "#### (2) 머신러닝 모델 생성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f2351fe4-6a77-405f-b860-00b9c0a13f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 머신러닝 모델 생성하기\n",
    "# 모델 생성 시 n_jobs 옵션이 있는 모델은 -1을 적용하여 동작 시키는 것을 권유함\n",
    "lr = LinearRegression( n_jobs=-1)\n",
    "dtr = DecisionTreeRegressor( random_state=1)\n",
    "rfr = RandomForestRegressor( random_state=1)\n",
    "gbr = GradientBoostingRegressor( random_state=1)\n",
    "xgbr = XGBRFRegressor(n_jobs=-1, random_state=1)\n",
    "etr = ExtraTreesRegressor(n_jobs=-1, random_state=1)\n",
    "lgbmr = LGBMRegressor(n_jobs=-1, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3c5b9c-bd3e-4dca-bf7d-c5c493a9f170",
   "metadata": {},
   "source": [
    "모델 생성까지 진행했으니 이제 학습을 해야 하는데 지금까지 한 작업을 고려했을 때 시험 데이터세트가 없습니다. 따라서 훈련 데이터세트를 만들고 학습하는 과정까지 진행합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "35bd9ff3-bb55-4fd6-9f09-21eda74bdc65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1500, 19), (1500,))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 훈련 데이터 분할하기\n",
    "x_train, x_test, y_train ,y_test = train_test_split(x, y , \n",
    "                   test_size=0.3,\n",
    "                   random_state=2023, # 서로 다른 결과를 나타내지 않기\n",
    "                )\n",
    "# shape 확인하기\n",
    "x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aaa746f2-2a46-4ba8-b0d2-57b100629f6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3500, 19), (3500,))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape 확인하기\n",
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d802a313-abc2-437b-a0a8-ef79e21d9137",
   "metadata": {},
   "source": [
    "#### (3) 머신러닝 모델 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3f06d493-6461-4803-8691-518d1fe39eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000086 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 231\n",
      "[LightGBM] [Info] Number of data points in the train set: 3500, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7548.349714\n",
      "CPU times: total: 2.77 s\n",
      "Wall time: 2.6 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMRegressor(n_jobs=-1, random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMRegressor</label><div class=\"sk-toggleable__content\"><pre>LGBMRegressor(n_jobs=-1, random_state=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMRegressor(n_jobs=-1, random_state=1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "# 머신러닝 모델(base 모델) 학습하기\n",
    "\n",
    "lr.fit(x_train, y_train)\n",
    "dtr.fit(x_train, y_train)\n",
    "rfr.fit(x_train, y_train)\n",
    "gbr.fit(x_train, y_train)\n",
    "xgbr.fit(x_train, y_train)\n",
    "etr.fit(x_train, y_train)\n",
    "lgbmr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc819af-e04c-4379-8122-acd158a403e8",
   "metadata": {},
   "source": [
    "모델 학습이 완료되면 이제 각 모델별 성능 평가를 진행합니다. 이것은 회귀분석이므로 모델이 데이터에 얼마나 적합한지 확인할 수 있는 r2 score를 바탕으로 기본 검증을 진행합니다. \n",
    "\n",
    "#### (4) 머신러닝 모델 성능 비교하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f3f441d0-b02b-4922-b3ca-6ff13ca884b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr</th>\n",
       "      <th>dtr</th>\n",
       "      <th>rfr</th>\n",
       "      <th>gbr</th>\n",
       "      <th>xgbr</th>\n",
       "      <th>etr</th>\n",
       "      <th>lgbmr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>r2</th>\n",
       "      <td>0.61523</td>\n",
       "      <td>0.70927</td>\n",
       "      <td>0.79828</td>\n",
       "      <td>0.76376</td>\n",
       "      <td>0.73102</td>\n",
       "      <td>0.74807</td>\n",
       "      <td>0.79957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse</th>\n",
       "      <td>2818.92861</td>\n",
       "      <td>2450.35112</td>\n",
       "      <td>2041.08811</td>\n",
       "      <td>2208.84675</td>\n",
       "      <td>2356.92955</td>\n",
       "      <td>2280.97506</td>\n",
       "      <td>2034.53417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              lr         dtr         rfr         gbr        xgbr         etr  \\\n",
       "r2       0.61523     0.70927     0.79828     0.76376     0.73102     0.74807   \n",
       "rmse  2818.92861  2450.35112  2041.08811  2208.84675  2356.92955  2280.97506   \n",
       "\n",
       "           lgbmr  \n",
       "r2       0.79957  \n",
       "rmse  2034.53417  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결과 검증용 라이브러리 불러오기\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 리스트에 모델 입력하기\n",
    "models = [lr, dtr, rfr, gbr, xgbr, etr, lgbmr]\n",
    "\n",
    "\n",
    "r2_score_list = []\n",
    "rmse_score_list = []\n",
    "\n",
    "# 모델 결과 확인하기\n",
    "for model in models:\n",
    "    pred = model.predict(x_test)\n",
    "    r2_score_list.append(\n",
    "        round(r2_score(y_test, pred),5)\n",
    "    )\n",
    "    # squared를 False로 하면 RMSE가 됨\n",
    "    rmse_score_list.append(\n",
    "        round(mean_squared_error(\n",
    "            y_test, pred, squared=False),5)\n",
    "    ) \n",
    "    \n",
    "r2_score_df = pd.DataFrame([r2_score_list, rmse_score_list], \n",
    "                           columns=[\"lr\", \"dtr\", \"rfr\", \"gbr\", \"xgbr\", \"etr\",\"lgbmr\"],\n",
    "                           index=[\"r2\", \"rmse\"]\n",
    "                          )\n",
    "\n",
    "r2_score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eeff9fa-5ab7-4124-a308-bd318bf54aba",
   "metadata": {},
   "source": [
    "실행 결과를 확인했을 때, r2 score가 79.9%로 boosting 기반의 LGBM이 가장 좋은 성능을 보여줍니다.<br>\n",
    "이 모델을 바탕으로 모델 개선을 진행합니다. 머신러닝 강의에서는 하이퍼파라미터에 대해 간단히 짚고 넘어갈 뿐 어떻게 적용하는지 설명하지 않습니다. 하이퍼파라미터 튜닝은 일반적으로 통용되는 방법이 있지만 명확히 특정 값이 좋다는 것을 한 번에 알 수 있는 방법은 없습니다. 그러면 직관적으로 생각했을 때, 쉽게 시도해 볼 수 있는 방법은 다 입력해 봅니다. 이번에는 모든 후보 하이퍼파라미터를 대입해 보는 GridSearchCV를 통해 성능을 개선해 봅니다. 말 그대로 주어지는 경우의 수를 전부 대입하기 때문에 시간이 오래 걸립니다. \n",
    "\n",
    "### 4) 최적의 하이퍼파리미터 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d9a89c70-d5b9-4749-8193-a9b301011c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000074 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 223\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7601.929643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000042 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7576.702500\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000038 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 221\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7485.184643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000040 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7503.671429\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000038 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 224\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7574.260357\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000042 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 223\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7601.929643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000049 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7576.702500\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000041 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 221\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7485.184643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000056 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7503.671429\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000075 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 224\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7574.260357\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000163 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 223\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7601.929643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000187 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7576.702500\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000064 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 221\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7485.184643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000170 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7503.671429\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000182 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 224\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7574.260357\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000044 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 223\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7601.929643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000049 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7576.702500\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000175 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 221\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7485.184643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000040 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7503.671429\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000172 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 224\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7574.260357\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000040 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 223\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7601.929643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000041 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7576.702500\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000039 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 221\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7485.184643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000123 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7503.671429\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000139 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 224\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7574.260357\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000039 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 223\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7601.929643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000039 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7576.702500\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000036 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 221\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7485.184643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000041 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7503.671429\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000028 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 224\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7574.260357\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000041 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 223\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7601.929643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000040 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7576.702500\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000093 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 221\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7485.184643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000038 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7503.671429\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000037 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 224\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7574.260357\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000040 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 223\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7601.929643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000043 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7576.702500\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000042 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 221\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7485.184643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000146 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7503.671429\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000036 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 224\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7574.260357\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000042 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 223\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7601.929643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000038 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7576.702500\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000038 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 221\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7485.184643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000054 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7503.671429\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000038 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 224\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7574.260357\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000178 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 223\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7601.929643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000070 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7576.702500\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000254 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 221\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7485.184643\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000215 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7503.671429\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000296 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 224\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7574.260357\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000046 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 223\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7601.929643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000047 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7576.702500\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000045 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 221\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7485.184643\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000177 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7503.671429\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000045 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 224\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7574.260357\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000046 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 223\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7601.929643\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000197 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7576.702500\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000068 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 221\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7485.184643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000044 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7503.671429\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000213 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 224\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7574.260357\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000191 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 223\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7601.929643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000046 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7576.702500\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000073 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 221\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7485.184643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000046 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7503.671429\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000042 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 224\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7574.260357\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000172 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 223\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7601.929643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000044 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7576.702500\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000048 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 221\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7485.184643\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023438 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7503.671429\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000040 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 224\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7574.260357\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000046 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 223\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7601.929643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000042 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7576.702500\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000048 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 221\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7485.184643\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000260 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7503.671429\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000049 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 224\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7574.260357\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000180 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 223\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7601.929643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000038 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7576.702500\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000040 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 221\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7485.184643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000051 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7503.671429\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000042 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 224\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7574.260357\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000047 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 223\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7601.929643\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000187 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7576.702500\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000045 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 221\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7485.184643\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000175 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7503.671429\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000044 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 224\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7574.260357\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000070 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 223\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7601.929643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000041 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7576.702500\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000045 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 221\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7485.184643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000063 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7503.671429\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000035 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 224\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7574.260357\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000045 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 231\n",
      "[LightGBM] [Info] Number of data points in the train set: 3500, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7548.349714\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 30}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GridSearchCV 라이브러리 불러오기\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 비교 하이퍼파라미터 선정하기\n",
    "param_grid = { \n",
    "    'learning_rate': [0.1 ,0.01, 0.003],\n",
    "    'colsample_bytree': [0.5, 0.7],\n",
    "    'max_depth' : [ 20,30,40],\n",
    "}\n",
    "\n",
    "# 최적 하이퍼파라미터 검색하기\n",
    "cv_lgbmr = GridSearchCV(estimator=lgbmr,\n",
    "                      param_grid=param_grid,\n",
    "                      cv= 5,\n",
    "                      verbose=1\n",
    "                     )\n",
    "\n",
    "cv_lgbmr.fit(x_train, y_train)\n",
    "\n",
    "# 최적 하이퍼파라미터 조합 확인하기\n",
    "cv_lgbmr.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03552659-3dbe-4d0d-8566-4bf5533a6908",
   "metadata": {},
   "source": [
    "좀 더 해 볼 여지는 있겠지만 찾은 파라미터를 바탕으로 LGBM에 적용하여 개선되었는지 확인합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9e4822fe-f956-4670-8ef9-370d47b1e28c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000814 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 231\n",
      "[LightGBM] [Info] Number of data points in the train set: 3500, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7548.349714\n",
      "r2 :  0.80154\n",
      "rmse :  2024.49371\n"
     ]
    }
   ],
   "source": [
    "# 머신러닝 모델 검증하기\n",
    "# 최적의 하이퍼파라미터로 재학습하기\n",
    "best_lgbmr = LGBMRegressor(max_depth= 30, \n",
    "                                 colsample_bytree= 0.7,\n",
    "                                 learning_rate= 0.1,\n",
    "                                 n_jobs=-1,\n",
    "                                 random_state= 1\n",
    "                                )\n",
    "best_lgbmr.fit(x_train,y_train)\n",
    "\n",
    "# 모델 성능 검증하기\n",
    "b_pred=best_lgbmr.predict(x_test)\n",
    "print('r2 : ', round(r2_score(y_test, b_pred),5))\n",
    "print('rmse : ', round(mean_squared_error(y_test, b_pred, squared=False),5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc76b76-5c56-43af-af4b-77c38c63f2ae",
   "metadata": {},
   "source": [
    "그리드 서치를 통해 학습한 결과, 앞서 기본 파라미터로 학습한 LGBM의 r2 score 0.79957 대비 성능이 향성된 것을 확인할 수 있습니다.<br>\n",
    "다음은 앞서 이론에서 설명한 내용 중 GridSearchCV 외에 RandomizedSearchCV를 활용해 최적의 파라미터를 구하는 방법을 추가로 알아봅니다. GridSearch CV는 범위 내 값을 랜덤한 조합으로 Search를 진행하여 빠른 편입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "36b4d289-c01c-4160-89f3-699e3f8ed78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomizedSearchCV 라이브러리 호출하기\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# 비교 파라미터 선정하기\n",
    "param_dists = { \n",
    "    'learning_rate': [0.1 ,0.01, 0.003],\n",
    "    'colsample_bytree': [0.5, 0.7],\n",
    "    'max_depth' : [20, 30, 40],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b124f1f3-0d61-4c1a-b61c-05413b2cfd72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ubion\\anaconda3\\envs\\aitensor\\lib\\site-packages\\sklearn\\model_selection\\_search.py:307: UserWarning: The total space of parameters 18 is smaller than n_iter=500. Running 18 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000321 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 223\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7601.929643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000035 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7576.702500\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000045 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 221\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7485.184643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000037 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7503.671429\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000036 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 224\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7574.260357\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000170 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 223\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7601.929643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000062 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7576.702500\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000039 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 221\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7485.184643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000042 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7503.671429\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000035 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 224\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7574.260357\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000036 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 223\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7601.929643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000168 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7576.702500\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000039 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 221\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7485.184643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000042 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7503.671429\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000030 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 224\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7574.260357\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000172 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 223\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7601.929643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000032 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7576.702500\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000054 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 221\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7485.184643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000038 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7503.671429\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000036 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 224\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7574.260357\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000039 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 223\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7601.929643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000190 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7576.702500\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000136 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 221\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7485.184643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000039 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7503.671429\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000037 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 224\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7574.260357\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000038 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 223\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7601.929643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000037 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7576.702500\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000240 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 221\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7485.184643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000189 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7503.671429\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000193 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 224\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7574.260357\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000040 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 223\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7601.929643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000040 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7576.702500\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000039 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 221\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7485.184643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000271 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7503.671429\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000059 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 224\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7574.260357\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000177 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 223\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7601.929643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000037 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7576.702500\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000033 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 221\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7485.184643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000038 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7503.671429\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000028 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 224\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7574.260357\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000051 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 223\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7601.929643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000036 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7576.702500\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000040 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 221\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7485.184643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000163 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7503.671429\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000055 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 224\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7574.260357\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000044 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 223\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7601.929643\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000163 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7576.702500\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000048 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 221\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7485.184643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000045 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7503.671429\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000138 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 224\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7574.260357\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000066 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 223\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7601.929643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000059 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7576.702500\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000042 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 221\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7485.184643\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000279 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7503.671429\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000043 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 224\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7574.260357\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000046 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 223\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7601.929643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000045 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7576.702500\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000073 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 221\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7485.184643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000044 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7503.671429\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000040 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 224\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7574.260357\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000178 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 223\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7601.929643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000052 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7576.702500\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000043 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 221\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7485.184643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000045 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7503.671429\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000072 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 224\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7574.260357\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000059 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 223\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7601.929643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000049 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7576.702500\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000078 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 221\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7485.184643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000041 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7503.671429\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000037 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 224\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7574.260357\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000144 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 223\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7601.929643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000047 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7576.702500\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000046 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 221\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7485.184643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000061 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7503.671429\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000242 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 224\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7574.260357\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000187 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 223\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7601.929643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000050 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7576.702500\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000051 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 221\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7485.184643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000056 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7503.671429\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000285 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 224\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7574.260357\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000183 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 223\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7601.929643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000049 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7576.702500\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000042 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 221\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7485.184643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000048 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7503.671429\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000036 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 224\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7574.260357\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000165 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 223\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7601.929643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000044 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7576.702500\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000046 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 221\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7485.184643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000045 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7503.671429\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000054 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 224\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7574.260357\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000050 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 231\n",
      "[LightGBM] [Info] Number of data points in the train set: 3500, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7548.349714\n",
      "{'max_depth': 30, 'learning_rate': 0.1, 'colsample_bytree': 0.7}\n",
      "CPU times: total: 19.1 s\n",
      "Wall time: 6.72 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# 최적 파라미터 검색하기\n",
    "cv_lgbmr = RandomizedSearchCV(estimator=lgbmr,\n",
    "                      param_distributions=param_dists,\n",
    "                      n_iter=500,\n",
    "                      cv=5,\n",
    "                      verbose=1\n",
    "                     )\n",
    "\n",
    "cv_lgbmr.fit(x_train, y_train)\n",
    "\n",
    "# 최적의 파라미터 조합 확인하기\n",
    "print(cv_lgbmr.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297932ee-7a12-474b-99c6-ff4070c6dec5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa99cc62-499c-4900-abb8-6ef16f401b47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4de4f1-11ac-4911-9841-ed57661ac658",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63098a93-d830-4383-860f-eef6a901b98d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d67a72-dfef-497f-aa09-eace1f923f83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7c2677-4044-4a5f-8bdd-9da22440800a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d9f186-fde5-4c30-a99d-ba1808ba52b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
