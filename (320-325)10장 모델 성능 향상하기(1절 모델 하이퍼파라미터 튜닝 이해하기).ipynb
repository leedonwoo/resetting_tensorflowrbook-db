{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62fb54a8-5d85-4616-84cb-a6208e388423",
   "metadata": {},
   "source": [
    "# 1절 모델 하이퍼파라미터 튜닝 이해하기\n",
    "지금까지 머신러닝 모델의 성능을 높이기 위해서 학습 데이터 전처리와 정제, 데이터의 특징 선택과 추출, 그리고 여러 가지 머신러닝 모델을 테스트해 보았습니다. 이번에는 세부 튜닝 방법으로 하이퍼파라미터 조정을 통해 모델의 성능을 개선해 봅니다.<br> \n",
    "\n",
    "하이퍼파라미터는 모델을 훈련시킬 때 사용자가 직접 설정하는 값입니다. 학습률(learning rate), 의사결정나무의 최대 깊이(max depth) 값 등 사용자가 직접 설정해야 하는 파라미터 값이 상당히 많습니다. 전통적으로 하이퍼파라미터 튜닝은 수동으로 수행되었습니다. 해당 하이퍼파라미터 사용 사례와 관련 도메인 경험이 있는 사람이 경험과 직관에 따라 하이퍼파라미터를 수동으로 설정해서 모델을 훈련하고 검증하여 좋은 성능이 나올 때까지 반복했습니다. <br>\n",
    "수동으로 하이퍼파라미터를 튜닝하는 것은 노동 집약적이고 효율적인 방법이 아닙니다. 현재 하이퍼파라미터를 자동으로 튜닝하는 대표적인 기법으로는 그리드 서치(Grid Search)와 랜덤 서치(Random Search)가 있습니다. 사이킷런 라이브러리의 model_selection 서브패키지에 GridSearchCV, RandomizedSearchCV와 RandomizedSearchCV로 머신러닝 모델의 하이퍼파라미터를 튜닝하고 모델 성능을 개선해 봅니다. \n",
    "\n",
    "## 1. 그리드 서치\n",
    "### 1) 그리드 서치 이해하기\n",
    "그리드 서치(Grid Search)는 가능한 모든 하이퍼파라미터 값의 조합에 대해 모델 성능을 측정하고 비교하면서 최적의 하이퍼파라미터 값을 찾는 방식입니다. 모든 값을 탐색한다는 점에서 철저한 방식인 반면 시간이 많이 소요되는 비효율적인 방법일 수도 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f8c119-432c-4b33-b1f6-373594704fdf",
   "metadata": {},
   "source": [
    "### 2) 그리드 서치 실습하기\n",
    "사이킷런 라이브러리에서 제공하는 GridSearchCV를 사용하는 방법은 간단합니다. 사용자가 모델의 하이퍼파라미터 값을 리스트로 GridSearchCV에 입력하면, 리스트에 있는 값들의 모든 조합에 대해 모델 성능을 평가하여 최적의 조합을 찾습니다. 먼저 튜닝하려는 하이퍼파라미터의 값을 리스트로 지정하고 딕셔너리로 자료형을 구성합니다. 그리고 sklearn.model_selection 모듈에 있는 GridSearchCV 클래스의 객체를 만들고, estimator 객체를 훈련하고 튜닝합니다.<br> \n",
    "예제 코드에서는 그리드 서치를 사용하여 랜덤 포레스트 분류기의 여러 파라미터를 튜닝합니다. 해당 코드를 통해 사용법을 참고로 확인한 후 실습해 봅니다.<br>\n",
    "랜덤 포레스트 분류기의 하이퍼파라미터는 아래와 같습니다.<br> \n",
    "\n",
    "\n",
    "<div class=\"alert alert-block\" style=\"border: 2px solid #1976D2;background-color:#E3F2FD;padding:5px;font-size:0.9em;\">\n",
    "<b>| 하이퍼파라미터 |</b><br>\n",
    "* max_depth：랜덤 프로세트 모델에서 각 의사결정나무의 최대 깊이<br>\n",
    "* max_features：랜덤 포레스트 모델이 각 분할에서 시도할 수 있는 최대 특성 수<br>\n",
    "* n_estimators：의사결정나무 수<br>\n",
    "* min_samples_leaf：각 트리의 리프 노드에 있어야 하는 최소 샘플 수<br>\n",
    "* min_samples_split：각 트리의 내부 노드를 분할하는 데 필요한 최소 샘플 수\n",
    "</div>\n",
    "\n",
    "GridSearchCV클래스의 객체 생성 인자는 다음과 같습니다. \n",
    "* estimator：estimator 객체\n",
    "* param_grid：튜닝하려는 하이퍼파라미터의 딕셔너리를 지정\n",
    "* scoring：모델의 성능을 평가하는 전략으로, 기본값은 ‘accuracy’\n",
    "* n_jobs：병렬로 실행할 작업 수이며, -1은 모든 프로세서를 사용한다는 의미이고, 기본값은 1\n",
    "* refit：가장 최적의 하이퍼파라미터를 찾은 후 입력된 estimator 객체를 해당 하이퍼파라미터로 재학습시키는 것으로, 기본값은 True\n",
    "* cv：교차 검증을 위한 fold 횟수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e55b8c79-7755-4fff-82ee-29c420e43b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ubion\\anaconda3\\envs\\aitensor\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "432 fits failed out of a total of 1296.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "432 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ubion\\anaconda3\\envs\\aitensor\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ubion\\anaconda3\\envs\\aitensor\\lib\\site-packages\\sklearn\\base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\ubion\\anaconda3\\envs\\aitensor\\lib\\site-packages\\sklearn\\base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\ubion\\anaconda3\\envs\\aitensor\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of RandomForestClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\ubion\\anaconda3\\envs\\aitensor\\lib\\site-packages\\sklearn\\model_selection\\_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan 0.89166667 0.94166667 0.94166667\n",
      " 0.925      0.93333333 0.93333333        nan        nan        nan\n",
      " 0.925      0.95833333 0.94166667 0.94166667 0.94166667 0.94166667\n",
      "        nan        nan        nan 0.94166667 0.95       0.93333333\n",
      " 0.94166667 0.95833333 0.94166667        nan        nan        nan\n",
      " 0.95       0.95       0.95       0.95       0.95       0.95\n",
      "        nan        nan        nan 0.95       0.94166667 0.95\n",
      " 0.94166667 0.94166667 0.95833333        nan        nan        nan\n",
      " 0.95       0.94166667 0.96666667 0.95       0.94166667 0.96666667\n",
      "        nan        nan        nan 0.94166667 0.95       0.95\n",
      " 0.95833333 0.95       0.95              nan        nan        nan\n",
      " 0.95833333 0.95       0.95833333 0.925      0.95       0.95833333\n",
      "        nan        nan        nan 0.95       0.94166667 0.94166667\n",
      " 0.94166667 0.95       0.95              nan        nan        nan\n",
      " 0.95       0.95833333 0.95833333 0.94166667 0.95       0.95833333\n",
      "        nan        nan        nan 0.95       0.94166667 0.95\n",
      " 0.95       0.95       0.94166667        nan        nan        nan\n",
      " 0.95       0.95       0.95833333 0.94166667 0.95       0.95\n",
      "        nan        nan        nan 0.9        0.93333333 0.95\n",
      " 0.93333333 0.925      0.94166667        nan        nan        nan\n",
      " 0.94166667 0.94166667 0.94166667 0.95       0.93333333 0.93333333\n",
      "        nan        nan        nan 0.94166667 0.93333333 0.94166667\n",
      " 0.93333333 0.95833333 0.93333333        nan        nan        nan\n",
      " 0.95       0.95       0.95       0.93333333 0.95833333 0.95833333\n",
      "        nan        nan        nan 0.95       0.95833333 0.95833333\n",
      " 0.95       0.95       0.95              nan        nan        nan\n",
      " 0.93333333 0.95       0.94166667 0.95833333 0.94166667 0.94166667\n",
      "        nan        nan        nan 0.94166667 0.94166667 0.94166667\n",
      " 0.95       0.95       0.94166667        nan        nan        nan\n",
      " 0.93333333 0.94166667 0.95       0.95       0.94166667 0.95833333\n",
      "        nan        nan        nan 0.95833333 0.95833333 0.95\n",
      " 0.95833333 0.95833333 0.95              nan        nan        nan\n",
      " 0.93333333 0.94166667 0.95       0.94166667 0.95       0.95\n",
      "        nan        nan        nan 0.95       0.93333333 0.95833333\n",
      " 0.94166667 0.95833333 0.95833333        nan        nan        nan\n",
      " 0.94166667 0.95       0.95833333 0.94166667 0.96666667 0.95\n",
      "        nan        nan        nan 0.93333333 0.94166667 0.94166667\n",
      " 0.95       0.94166667 0.925             nan        nan        nan\n",
      " 0.94166667 0.93333333 0.95       0.96666667 0.95833333 0.94166667\n",
      "        nan        nan        nan 0.95       0.95       0.95\n",
      " 0.93333333 0.95833333 0.95833333        nan        nan        nan\n",
      " 0.95       0.95       0.95       0.95833333 0.95       0.95\n",
      "        nan        nan        nan 0.95       0.95833333 0.95\n",
      " 0.94166667 0.95833333 0.95833333        nan        nan        nan\n",
      " 0.94166667 0.94166667 0.95833333 0.95833333 0.96666667 0.95833333\n",
      "        nan        nan        nan 0.94166667 0.95       0.95\n",
      " 0.94166667 0.95       0.95              nan        nan        nan\n",
      " 0.95       0.95833333 0.95       0.95833333 0.95833333 0.95\n",
      "        nan        nan        nan 0.95833333 0.94166667 0.95\n",
      " 0.94166667 0.95       0.94166667        nan        nan        nan\n",
      " 0.90833333 0.95       0.95       0.95       0.95       0.95\n",
      "        nan        nan        nan 0.925      0.94166667 0.94166667\n",
      " 0.94166667 0.94166667 0.94166667        nan        nan        nan\n",
      " 0.94166667 0.96666667 0.96666667 0.925      0.96666667 0.95\n",
      "        nan        nan        nan 0.925      0.93333333 0.94166667\n",
      " 0.93333333 0.93333333 0.95              nan        nan        nan\n",
      " 0.925      0.925      0.925      0.91666667 0.93333333 0.95\n",
      "        nan        nan        nan 0.93333333 0.94166667 0.95\n",
      " 0.94166667 0.95       0.93333333        nan        nan        nan\n",
      " 0.93333333 0.95       0.94166667 0.91666667 0.95       0.95\n",
      "        nan        nan        nan 0.93333333 0.95       0.95833333\n",
      " 0.94166667 0.95833333 0.95              nan        nan        nan\n",
      " 0.93333333 0.95833333 0.95       0.93333333 0.95       0.94166667\n",
      "        nan        nan        nan 0.95       0.95       0.95\n",
      " 0.93333333 0.95833333 0.95              nan        nan        nan\n",
      " 0.94166667 0.94166667 0.94166667 0.93333333 0.95       0.95833333\n",
      "        nan        nan        nan 0.94166667 0.94166667 0.95833333\n",
      " 0.91666667 0.96666667 0.96666667        nan        nan        nan\n",
      " 0.95       0.95833333 0.94166667 0.95833333 0.95833333 0.95\n",
      "        nan        nan        nan 0.94166667 0.94166667 0.95833333\n",
      " 0.93333333 0.95       0.95              nan        nan        nan\n",
      " 0.94166667 0.95       0.95       0.93333333 0.96666667 0.96666667]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris  # 예시 데이터셋\n",
    "\n",
    "# 예시 데이터 로드 (Iris 데이터셋 사용)\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# 데이터셋을 훈련 세트와 테스트 세트로 나누기\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 그리드 서치를 위한 RandomForestClassifier 설정\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "estimator = RandomForestClassifier()\n",
    "\n",
    "param_grid = {'max_depth': [3, 5, 10, None],\n",
    "              'n_estimators': [10, 100, 200],\n",
    "              'max_features': [1, 3, 5, 7],\n",
    "              'min_samples_leaf': [1, 2, 3],\n",
    "              'min_samples_split': [1, 2, 3]}\n",
    "\n",
    "gs_cv = GridSearchCV(estimator=estimator,\n",
    "                     param_grid=param_grid,\n",
    "                     scoring='accuracy',\n",
    "                     cv=3)\n",
    "\n",
    "# 그리드 서치를 훈련 데이터에 적용\n",
    "model = gs_cv.fit(X_train, y_train)\n",
    "\n",
    "# 최적의 하이퍼파라미터와 성능 출력\n",
    "#print(\"Best Parameters:\", gs_cv.best_params_)\n",
    "#print(\"Best Score:\", gs_cv.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7048b059-999f-41bf-ab0f-8cc0cb002ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters : {'max_depth': 3, 'max_features': 3, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Best score : 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "print(f'Best hyperparameters : {model.best_params_}')\n",
    "print(f'Best score : {model.best_score_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f318e0a-03b4-41d7-87f2-407b10e6a398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 정확도 : 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "clf=model.best_estimator_\n",
    "clf.fit(X_train, y_train)\n",
    "print(f'테스트 정확도 : {clf.score(X_train, y_train)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fae2f52-81b2-466a-8340-6f48691f4e25",
   "metadata": {},
   "source": [
    "## 2. 랜덤 서치\n",
    "### 1) 랜덤 서치 이해하기\n",
    "랜덤 서치(Random Search)는 그리드 서치와 유사하지만 가능한 각 하이퍼파라미터 조합에 대해 훈련하고 점수를 매기는 대신 랜덤 조합이 선택됩니다. 시간 및 리소스 제약에 따라 검색 반복 횟수를 설정할 수 있으며, 파라미터 탐색 범위가 넓거나 연속적인 값을 탐색해야 하는 경우에 랜덤 서치가 효율적입니다. \n",
    "\n",
    "\n",
    "\n",
    "### 2) 랜덤 서치 실습하기\n",
    "튜닝하려는 매개변수들의 값을 리스트로 지정하고 딕셔너리로 변수를 만든 다음, sklearn.model_selection 모듈에 있는 RadnomizedSearchCV 클래스의 객체를 만들고, estimator 객체를 훈련하고 튜닝합니다. 예제 코드에서는 랜덤 서치를 사용하여 랜덤 포레스트 분류기의 여러 파라미터를 튜닝합니다. 해당 코드를 통해 사용법을 참고로 확인한 후 실습해 봅니다. \n",
    "\n",
    "> 하이퍼파라미터\n",
    "> <div class=\"alert alert-block\" style=\"border: 2px solid #1976D2;background-color:#E3F2FD;padding:5px;font-size:0.9em;\">\n",
    "    * max_depth：랜덤 포레스트 모델에서 각 의사결정나무의 최대 깊이<br>\n",
    "    * n_estimators：의사결정나무 수<br>\n",
    "    * criterion：분할 품질을 측정하는 기능<br>\n",
    "    * min_samples_leaf：각 트리의 리프 노드에 있어야 하는 최소 샘플 수<br>\n",
    "    * min_samples_split：각 트리의 내부 노드를 분할하는 데 필요한 최소 샘플 수</div>\n",
    "\n",
    "RandomizedSearchCV 클래스 객체 생성 인자는 다음과 같습니다.<br>\n",
    "* estimator：estimator 객체<br>\n",
    "* n_iter：파라미터 검색 횟수, 지정한 횟수만큼만 조합을 반복하여 평가, 기본값은 10<br>\n",
    "* param_distributions：튜닝하려는 하이퍼파라미터의 딕셔너리를 지정<br>\n",
    "* scoring：모델의 성능을 평가하는 전략으로, 기본값은 ‘accuracy’<br>\n",
    "* n_jobs：병렬로 실행할 작업수이며, -1은 모든 프로세서를 사용한다는 의미이고, 기본값은 1<br>\r",
    "* refit：가장 최적의 하이퍼파라미터를 찾은 후 입력된 estimator 객체를 해당 하이퍼파라미터로 재학습시키는 것으로, 기본값은 True<br>\n",
    "* cv：교차 검증을 위한 fold 횟수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d39b3655-530e-4a9d-98a3-7efcba5d3f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import randint\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# 모델 정의\n",
    "estimator = RandomForestClassifier()\n",
    "\n",
    "# 하이퍼파라미터 검색 범위 정의\n",
    "param_distributions = {'max_depth': list(np.arange(3, 13, step=3)) + [None],\n",
    "                       'n_estimators': np.arange(10, 320, step=100),\n",
    "                       'max_features': randint(1, 7),\n",
    "                       'criterion': ['gini', 'entropy'],\n",
    "                       'min_samples_leaf': randint(1, 4),\n",
    "                       'min_samples_split': np.arange(2, 8, step=2)}\n",
    "\n",
    "# RandomizedSearchCV 정의\n",
    "rs_cv = RandomizedSearchCV(estimator=estimator,\n",
    "                           param_distributions=param_distributions,\n",
    "                           n_iter=10,\n",
    "                           scoring='accuracy',\n",
    "                           n_jobs=-1,\n",
    "                           refit=True,\n",
    "                           cv=3)\n",
    "\n",
    "# 모델 학습\n",
    "model = rs_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacb3a26-59a2-4b34-93e6-7b0394e70c63",
   "metadata": {},
   "source": [
    "훈련 데이터세트를 사용하여 랜덤 서치를 실행한 후, 모델의 최적의 하이퍼파라미터 값은 best_params_ 속성에서, 모델의 최고 점수는 best_score_ 속성에서 확인할 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3523e7f5-d6d2-42ca-a8f1-f4f177e4177f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters : {'criterion': 'entropy', 'max_depth': 6, 'max_features': 1, 'min_samples_leaf': 1, 'min_samples_split': 6, 'n_estimators': 110}\n",
      "Best score : 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "print(f'Best hyperparameters : {model.best_params_}')\n",
    "print(f'Best score : {model.best_score_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1c652f-a3b8-465f-86c5-5b67eab2d925",
   "metadata": {},
   "source": [
    "테스트 데이터세트로 모델 성능을 평가합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d2f32cd-1b5e-490f-a773-9dd6be732a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 정확도 : 1.0\n"
     ]
    }
   ],
   "source": [
    "clf=model.best_estimator_\n",
    "clf.fit(X_train, y_train)\n",
    "print(f'테스트 정확도 : {clf.score(X_test, y_test)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
