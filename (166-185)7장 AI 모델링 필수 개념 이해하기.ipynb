{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e11a02cf-a0ed-42ab-8369-1273e6837749",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block\" style=\"border: 2px solid #9D5CBB;background-color:#EBDEF1;padding:5px;font-size:0.9em;\">\n",
    "학습중입니다. 창작물이 아니고 시중 도서입니다. 도서를 구매해주십시오. 개인학습후에 삭제 예정입니다.\n",
    "</div>\n",
    "#166"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3159c512-823d-4ce1-8bb4-8263d05eb1ab",
   "metadata": {},
   "source": [
    "# 1절. AI란 무엇인가?<BR>\n",
    "AI는 이미 우리 삶에 가까이 자리잡고 있습니다. 기존의 노동을 대신 수행하는 자동화 개념을 넘어서, 인공지능이라는 뜻에 걸맞게 컴퓨터가 스스로 학습하며 많은 일들을 수행합니다. 따라서 우리는 시대의 흐름에 맞게 AI 기술을 활용할 수 있는 다양한 수단을 익혀야 합니다. <BR>\n",
    "AI에 관심 있는 사람들은 '머신러닝'과 '딥러닝'이라는 단어를 들어봤을 것입니다. 이는 AI를 활용하는 다양한 방법 중 가장 널리 사용되는 2가지 방식입니다.<BR>\n",
    "## 1. 머신러닝 이해하기\n",
    "머신러닝은 컴퓨터가 다양한 머신러닝 학습 모델을 기반으로 제공된 데이터를 이용해 학습을 수행하고, 모델의 성능을 반복적으로 평가하며, 스스로 성능을 향상시키는 것을 말합니다. 제공된 각 데이터별 상관관계와 특성을 찾아내고 결론을 예측할 수 있습니다. <BR>\n",
    "\n",
    "머신러닝은 데이터를 설명할 수 있는 하나의 함수를 찾는 것과 유사합니다. 위 그림은 최초에 데이터가 하나일 때부터 데이터가 증가함에 따라 데이터를 가장 잘 설명할 수 있는(즉, 데이터가 오차가 가장 적은) 함수를 예측해 나가는 과정입니다. <BR>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "881aea75-14f2-43c7-8d1e-c3bcde8ea2cb",
   "metadata": {},
   "source": [
    "#167"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3fff5e-15a2-4938-9007-62eb8ca61037",
   "metadata": {},
   "source": [
    "이렇게 하나의 함수를 만들면 그것을 활용해 사용자가 임의의 X를 입력했을 때 어떤 y가 나올지를 예측할 수 있습니다.<br>\n",
    "머신러닝도 여러 데이터를 기반으로 하나의 모델을 생성하고 여기에 데이터를 넣으면 예측 결과를 알 수 있는 원리입니다. 다만 개발되어 있는 다양한 머신러닝 모델을 활용하면, 사람이 함수를 직접 구할 필요 없이 입력된 데이터를 토대로 최적의 모델을 생성해주는 것이 진정한 머신러닝입니다.\n",
    "\n",
    "## 2. 딥러닝 이해하기<br>\n",
    "딥러닝은 머신러닝과는 구분되는 개념이지만, 큰 틀에서는 머신러닝이 포함되 기술입니다. 딥러닝은 인간의 뇌 신경망이 학습하는 방식에서 영감을 얻어, 머신러닝에 신경망 네트워크를 더해 만들었습니다. \n",
    "\n",
    "사람의 뇌에 있는 신경망은 시냅스 간 전기신호를 주고받으며 정보를 전합니다. 딥러닝은 이 개념을 도입해 레이어를 겹겹이 쌓고, 레이어 내 노드를 구성하여, 각 노드가 그물처럼 연결되어 학습을 진행합니다. 각 노드는 머신러닝 모델 하나의 역할을 수행하며 데이터를 입력받고 학습하여 가중치 W를 구합니다. 최종적으로 모든 레이어를 거치면 전체 학습의 성능을 평가하게 되고, 오차 역전파를 통해 딥러닝 모델의 성능을 향상시키기 위한 가중치 W를 재계산하는 과정을 반복 수행합니다. <BR>\n",
    "이러한 학습 방법에서 알 수 있듯이, 딥러닝은 머신러닝에 비해 연산이 기하급수적으로 늘어남에 따라, 성능은 뛰어나지만 연산에 필요한 자원이나 시간이 오래 소요된다는 점을 참고하여 학습을 진행해야 합니다. \n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cc750464-61c2-44b4-a958-408ffe341159",
   "metadata": {},
   "source": [
    "#168"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e41278-6ce7-4c60-bacc-fbf75bff1292",
   "metadata": {},
   "source": [
    "# 2절. AI 학습 방법 이해하기<BR>\n",
    "AI 학습은 크게 '지도학습', '비지도학습', '강화 학습' 3가지로 분류됩니다. 여기에서는 '지도학습', '비지도학습' 2가지를 설명합니다.<P>\n",
    "## 1. 지도학습 이해하기\n",
    "지도학습은 정답을 알려주며 학습시키는 방식입니다. 지도학습은 어린아이를 가르치는 것과 같습니다. 예를 들어 아이에게 동그라미와 세모를 구분하는 방법을 가르치는 상황을 떠올려 봅니다. 아이는 ○와 △의 모양이 다르다는 것을 인지할 수 있지만, 무엇이 동그라미이고, 세모인지 알 수 없습니다. 하지만 아이에게 '○=동그라미', '△=세모'라고 정답을 반복해서 알려주면 학습을 통해 동그라미와 세모를 분류할 수 있습니다. \n",
    "\n",
    "이처럼 지도학습은 문제의 정답이 있어야만 학습을 진행할 수 있고, 정답은 레이블이라고도 불리며, 데이터에 레이블을 입력해주는 것을 레이블링이라고 합니다. <BR>\n",
    "지도학습은 크게 '회귀'와 '분류'로 나뉩니다. AI를 수행하여 확인하고자 하는 결괏값의 형태가 무엇이냐에 따라 '회귀 모델' 또는 '분류 모델'을 적절히 선택해야 합니다. 예시를 통해 나에게 필요한 것이 회귀 모델인지 분류 모델인지를 구분하는 방법을 알아봅니다. "
   ]
  },
  {
   "cell_type": "raw",
   "id": "dfb1baa3-cf4f-47bb-8c11-fb48fdaa9d21",
   "metadata": {},
   "source": [
    "#169"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5199fc9-08ff-4335-ba17-181f5561b3b2",
   "metadata": {},
   "source": [
    "어느 자격증 학원에서 수강생들의 정보를 가지고 시험 점수 또는 합격 여부를 예측하는 AI 모델을 개발한다고 가정해 봅니다. 아래 표는 학습 데이터의 일부입니다. \n",
    "\n",
    "\n",
    "수강 정보를 가지고 수강생의 '시험 점수'를 예측할 경우 '회귀 모델'로 학습을 수행하면 됩니다. 회귀 모델에 수강 정보를 넣으면 해당 수강생의 시험 점수를 예측하는 모델을 만들 수 있습니다. 하지만 '합격 여부'만을 예측할 경우 '분류 모델'로 학습을 수행하면 됩니다. 분류 모델에 수강 정보를 넣으면 해당 수강생이 합격일지, 불합격일지 예측하는 모델을 만들 수 있습니다. \n",
    "'회귀'는 양적 데이터, 즉 점수와 같이 연속된 어떠한 값을 예측하는 모델이고, '분류'는 합격 불합격과 같은 범주형 데이터, 즉 어떤 종류를 예측하는 모델입니다. AI를 활용해 예측하고자 하는 결과가 무엇인지 분명히 정의하여 적절한 AI 모델을 선정해야 성공적인 AI 모델링을 진행할 수 있습니다. \n",
    "참고로 분류 모델의 경우 분류하고자 하는 값이 '합격/불합격', '0/1'과 같이 2가지인 경우에는 '이진 분류',<BR>\n",
    "'사과/딸기/바나나/수박'과 같이 여러 가지인 경우에는 '다중 분류'로 구분할 수 있습니다. \n",
    "\n",
    "## 2. 비지도학습 이해하기\n",
    "비지도학습은 정답이 없는 상태에서 입력 데이터만 가지고 학습하는 방법입니다. 정답, 즉 '레이블'이 없기 때문에 구체적인 결괏값이 아니라 '군집화'를 예측할 때 주로 사용됩니다.<br>\n",
    "군집화란 주어진 데이터를 기반으로 그 값이 유사한 데이터들의 그룹을 나누는 것입니다. 군집화 알고리즘 중 대표적인 'k-means 군집화'에서 'k'란 입력된 데이터를 몇 개의 그룹으로 나누느냐 하는 것입니다. k값은 사용자가 선택해야 하며, k개 군집의 중심점부터 가장 가까운 데이터들을 그룹핑한 결과입니다. "
   ]
  },
  {
   "cell_type": "raw",
   "id": "43bd97ea-c2d6-4208-a0e1-8eb8b07e1fcf",
   "metadata": {},
   "source": [
    "#170"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5b3911-4fca-49a3-9873-267f1db05dec",
   "metadata": {},
   "source": [
    "사용자가 레이블을 입력하는 과정이 없지만, 입력된 데이터들의 정보를 기반으로 알고리즘이 자체적으로 유사도를 판단하여 군집화를 수행합니다."
   ]
  },
  {
   "cell_type": "raw",
   "id": "92cbcf83-e69b-4605-ad13-252c03ef5843",
   "metadata": {},
   "source": [
    "#171"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9ccac6-a823-4a94-9b2a-e96ed1a0fcf7",
   "metadata": {},
   "source": [
    "# 3절. AI 모델링 프로세스 이해하기\n",
    "AI를 통한 학습은 목적과 데이터의 형태에 따라 다양한 방식으로 수행되지만, 전반적인 학습 프로세스를 이해하느 것이 중요합니다. 이번 섹션에서는 AI 모델링 프로세스의 각 단계에 대한 핵심 개념을 중심으로 살펴봅니다. AI 모델의 학습 방법에 대해서는 앞으로 이어지는 과정에서 자세히 학습할 예정입니다.\n",
    "\n",
    "## 1. AI 모델링 프로세스\n",
    "AI 학습은 일반적으로 다음 프로세스로 진행됩니다.\n",
    "\n",
    "\n",
    "6가지 프로세스를 수행하며 목표로 하는 AI 모델의 성능이 나올 때까지 데이터 전처리, 다양한 AI 모델 활용, 각종 파라미터 변경 등을 반복합니다.<BR>\n",
    "### 1) 데이터 확인\n",
    "학습에 활용할 데이터를 확인하는 과정입니다. 앞서 배운 것처럼 데이터를 획득하고 구조를 확인하고 이해하는 작업을 통해 주어진 데이터가 테이블 데이터인지, 사진 데이터인지, 영상 데이터인지 등 데이터 구조부터 데이터 유형, 자연어 처리 여부, 결측치 이상치, 중복, 분포도, 레이블링 여부 등 학습에 영향을 미칠 수 있는 모든 요소들을 확인해야 합니다. \n",
    "\n",
    "### 2) 데이터 전처리\n",
    "데이터 확인과정에서 파악한 내용을 토대로 학습을 수행하기 위해 데이터를 가공하는 과정입니다. 중복된 데이터를 제거하거나, 결측된 데이터를 특정 값으로 채워 넣거나, 학습에 필요 없는 데이터를 제외하는 작업 등이 포함됩니다. "
   ]
  },
  {
   "cell_type": "raw",
   "id": "2a092167-8d71-42f3-b099-f08cd4cc535c",
   "metadata": {},
   "source": [
    "#172"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55614818-87e8-4627-b544-017e65015b32",
   "metadata": {},
   "source": [
    "또한 주어진 데이터의 상관관계 등을 파악하여 새로운 데이터를 생성하거나 문자를 숫자로 변환하는 인코딩 작업까지, AI 학습을 위해 데이터를 가공하는 모든 작업을 '데이터 전처리'라고 합니다. <BR>\n",
    "이 과정은 초기에 한 번으로 끝나는 것이 아니라 학습을 모두 수행한 후에 모델의 성능을 평가하고 성능을 향상하기 위해 데이터의 추가적인 가공이 필요하다면 반복적으로 수행됩니다. \n",
    "\n",
    "### 3) AI 모델 선정\n",
    "학습을 수행할 AI 모델을 선정하는 과정입니다. 데이터의 형태에 따라 사용할 수 있는 AI 모델이 구분되어 있으며, 결괏값이 '회귀'인지 '분류'인지에 따라서도 적절한 모델을 선정해야 합니다. 또한 AI 학습은 경우에 따라 막대한 컴퓨팅 시스템 자원과 시간이 소요되므로 투입할 수 있는 자원과 시간을 감안해 적절한 수준의 AI 모델을 선정해야 합니다. 학습이 마무리된 이후에 성능을 향상해야 한다면, AI 모델을 바꿔보거나 하이퍼파라미터(AI 모델의 세부 설정값)를 조정하는 등 성능 향상을 위해 반복적으로 수행해야 하는 과정입니다.\n",
    "\n",
    "### 4) 학습 데이터 분할\n",
    "일반적으로 AI 학습 과정에서 과적합 방지 및 성능 평가를 위해 학습 데이터를 분할하여 사용합니다. 데이터를 분할하는 방식은 다음과 같습니다. \n",
    "\n",
    "\n",
    "주어진 학습 데이터 전체를 대상으로 용도에 따라 훈련, 검증, 테스트로 분할하며, 비율은 보통 a : b : c 기준으로 6 : 2 : 2 또는 7 : 2 : 1 등으로 지정합니다. 학습 데이터를 분할하는 이유는 학습을 통해 생성된 모델의 성능을 평가하기 위해서입니다. 전체 데이터를 모두 학습 데이터로만 사용한다면 학습 후 모델이 생성되었을 때, 학습에 포함된 데이터로 검증할 수밖에 없고, 그렇게 되면 모델의 정확도는 항상 100%로 나올 것입니다. "
   ]
  },
  {
   "cell_type": "raw",
   "id": "636bb4b0-bfbf-4376-ac7e-71aade4af36c",
   "metadata": {},
   "source": [
    "#173"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54ce12d-8758-4f88-828f-5f30ee47f835",
   "metadata": {},
   "source": [
    "데이터 분할하여 사용하는 예시는 다음과 같습니다. \n",
    "\n",
    "AI 모델은 학습 데이터를 활용해 반복적으로 모델을 생성합니다. 그리고 각 모델마다 성능을 측정하는데 이것을 검증 작업이라고 합니다. 예를 들어 세 번의 학습으로 A, B, C  3개의 모델이 생성되었고, 학습에 쓰이지 않은 검증 데이터로 정확도를 검증했을 때, 각각 72%, 88%, 80%로 측정되었습니다. 이를 통해 모델 B가 가장 좋은 성능을 가진 것으로 추측하여 최상의 모델로 선정할 수 있습니다. \n",
    "마지막 테스트 과정은 검증 이휑 수행되는데, 여러 번의 과정에서 운 좋게 성능이 좋은 것으로 측정될 수도 있으므로 이런 오차를 줄이기 위해 한 번도 훈련에 사용되지 않은 데이터를 사용한 테스트 과정을 추가로 진행합니다. \n",
    "<div style=\"display:table; border-collapse:collapse; width:50%; text-align:center;\">\n",
    "    <div style=\"display:table-row; background-color:#d9e2f3; font-weight:bold;\">\n",
    "        <div style=\"display:table-cell; border:1px solid black; padding:5px;\">사용 여부</div>\n",
    "        <div style=\"display:table-cell; border:1px solid black; padding:5px;\">Training dataset</div>\n",
    "        <div style=\"display:table-cell; border:1px solid black; padding:5px;\">Validation dataset</div>\n",
    "        <div style=\"display:table-cell; border:1px solid black; padding:5px;\">Test dataset</div>\n",
    "    </div>\n",
    "    <div style=\"display:table-row;\">\n",
    "        <div style=\"display:table-cell; border:1px solid black; padding:5px;\">학습 과정</div>\n",
    "        <div style=\"display:table-cell; border:1px solid black; padding:5px;\">O</div>\n",
    "        <div style=\"display:table-cell; border:1px solid black; padding:5px;\">O</div>\n",
    "        <div style=\"display:table-cell; border:1px solid black; padding:5px;\">X</div>\n",
    "    </div>\n",
    "    <div style=\"display:table-row;\">\n",
    "        <div style=\"display:table-cell; border:1px solid black; padding:5px;\">모델 가중치 설정</div>\n",
    "        <div style=\"display:table-cell; border:1px solid black; padding:5px;\">O</div>\n",
    "        <div style=\"display:table-cell; border:1px solid black; padding:5px;\">X</div>\n",
    "        <div style=\"display:table-cell; border:1px solid black; padding:5px;\">X</div>\n",
    "    </div>\n",
    "    <div style=\"display:table-row;\">\n",
    "        <div style=\"display:table-cell; border:1px solid black; padding:5px;\">모델 성능평가</div>\n",
    "        <div style=\"display:table-cell; border:1px solid black; padding:5px;\">X</div>\n",
    "        <div style=\"display:table-cell; border:1px solid black; padding:5px;\">O</div>\n",
    "        <div style=\"display:table-cell; border:1px solid black; padding:5px;\">O</div>\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "### 5) 모델 학습\n",
    "선정한 AI 모델을 활용해 데이터를 입력하여 결과를 예측할 수 있도로 학습하는 과정입니다. AI 알고리즘별로 다양한 방식의 학습이 진행되면, AI 모델별 학습 과정은 이후에도 실습과 함께 좀 더 상세히 다룰 예정입니다. "
   ]
  },
  {
   "cell_type": "raw",
   "id": "209e8745-76c6-4cd6-b728-f0be7112fc1c",
   "metadata": {},
   "source": [
    "#174"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea05b0b-f9aa-452b-a2a6-c198e9a37e7a",
   "metadata": {},
   "source": [
    "### 6) 성능 평가\n",
    "학습이 완료되면 검증 데이터와 테스트 데이터를 활용해 학습된 모델의 성능을 평가합니다. 성능 평가에서 목표했던 정확도에 도달하지 않으면 데이터를 추가로 진행하거나, AI 모델을 바꿔 보고, 각종 파라미터를 변경해 가면서, 목표치에 부합할 때까지 학습과 성능 평가를 반복 수행합니다. <BR>\n",
    "성능을 평가하는 지표는 다양합니다. 예측하고자 하는 출력값의 형태가 분류인지 회귀인지에 따라서 성능 평가 방법이 달라지며, 평가에 활용되는 다양한 지표들도 있습니다. 해당 내용도 이후 과정에서 상세히 다룰 예정입니다. "
   ]
  },
  {
   "cell_type": "raw",
   "id": "960f9931-605c-4c84-986e-755885173e0f",
   "metadata": {},
   "source": [
    "#175"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74dbaf0d-e391-4843-a0dd-01f90d55c8cd",
   "metadata": {},
   "source": [
    "# 4절. 학습 데이터의 분할 방법 이해하기\n",
    "AI 모델링을 본격적으로 수행하기 위해 학습 데이터를 훈련 데이터와 검증 데이터로 분할하는 방법과 이를 활용하는 방법을 좀더 자세히 알아봅시다. \n",
    "\n",
    "## 1. 학습 데이터 분할하기\n",
    "사이킷런 패키지에서 제공하는 `train_test_split` 함수는 데이터를 분할하는 데 가장 보편적으로 쓰이는 함수입니다. 사용자가 전체 데이터를 직접 나눌 수도 있지만, 굉장히 번거롭고 학습에 적합하도록 분배하기도 어렵습니다. `train_test_split` 함수를 활용하면 코드 단 한 줄로 손쉽게 데이터를 분할할 수 있습니다.  \n",
    "\n",
    "`train_test_split` 함수의 구조와 입력하는 방법은 다음과 같습니다. \n",
    "<div class=\"alert alert-block\" style=\"border: 2px solid #1976D2;background-color:#E3F2FD;padding:5px;font-size:0.9em;\">\n",
    "x_train, x_valid, y_train, y_valid=train_test_split(data, target, test_size=None, train_size=Noe, random_state=None, shuffle=True, stratify=None)\n",
    "</div>\n",
    "\n",
    "코드의 구조를 예시로 알아봅니다. 그림에 기입된 테이블은 이전 과정에서 나왔던 분류 데이터 중 일부입니다. 예측에 쓰일 입력값을 X, 맞춰야 하는 정답인 레이블을 Y라고 합니다. X와 Y가 `train_test_split`을 통해 학습용/검증용(x_train, x_valid, y_train, y_valid)으로 분할되는 과정을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "raw",
   "id": "92f9efd2-fd91-47a9-bd91-0d6b78a85524",
   "metadata": {},
   "source": [
    "#176"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2449f1-ebbf-4fcc-b372-29ac394cb9ff",
   "metadata": {},
   "source": [
    "또한 `train_test_split` 함수를 사용할 때는 다음과 같은 파라미터들을 적용할 수 있습니다. \n",
    "- `test_size` : 입력 타입은 float, int, 기본값은 none입니다. 입력 타입이 float인 경우 0.0에서 1.0 사이의 값이 입력되어야 하며, 값의 의미는 전체 데이터 중 test 데이터의 비율을 나타냅니다. \n",
    "- `train_size` : 입력 타입은 float 또는 int, 기본값은 none입니다. 입력 타입이 float인 경우 0.0에서 1.0 사이여야 하며, 값의 의미는 전체 데이터 중 train 데이터의 비율을 나타냅니다.\n",
    "- `random_state` : 입력 타입은 int, 기본값은 none입니다. 데이터 분할을 수행하기 전에 데이터에 적용되는 셔플링(데이터를 뒤섞는 작업)을 제어합니다. 이 값을 일정한 int값으로 통일한다면 train_test_split을 매번 수행하더라도 동일하게 분할된 데이터세트를 활용할 수 있습니다. \n",
    "- `shuffle` : 입력 타입은 True이거나 False, 기본값은 True입니다. 분할하기 전에 데이터를 섞을지 여부를 결정하는 요소입니다. `shuffle=False`인 경우 `stratify` 매개변수는 `none`이어야 합니다.<br>\n",
    "`stratify`가 입력(`none`일 때)되지 않으면, 데이터 분할 과정에서 데이터의 쏠림이 발생할 수 있습니다. 그림은 극단적인 예를 든 것이지만 데이터가 많더라도 쏠림 현상은 학습과 검증 과정에서 예기치 않은 문제를 야기할 수 있습니다. 특히 분류에서 큰 리스크로 작용할 수 있습니다. <br>\n",
    "반면 `stratify=Target`으로 입력하면, 데이터 분할에서 자동을 기존 Target의 데이터 분포 비율을 유지하여, 분할 후에도 동일한 분포를 가지도록 설정할 수 있습니다.\n",
    "\n",
    "\n",
    "## 2. k-fold 교차 검증하기\n",
    "전체 데이터를 학습용과 검증용으로 나누는 과정을 진행해 보았는데, 이런 의문이 들 수 있습니다. '하나의 검증 데이터세트로 한 번만 평가하기보다 다른 데이터세트로 여러 번 평가하면 더 정확하게 검증할 수 있지 않을까?' 그래서 나온 방법이 k-fold 교차 검증입니다. \n",
    "\n",
    "k-fold 교차 검증 과정을 순서대로 알아봅니다."
   ]
  },
  {
   "cell_type": "raw",
   "id": "f480dd92-cfb3-4b69-8a4f-3879158d593b",
   "metadata": {},
   "source": [
    "#177"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2608aff6-d730-44de-a7d9-3de8155c0eb0",
   "metadata": {},
   "source": [
    "### 1) k-fold 분할\n",
    "기본 방식과 다르게 k-fold 분할 방식은 다음과 같이 전체 데이터를 k개로 분할합니다. \n",
    "\n",
    "\n",
    "\n",
    "### 2) 교차 검증\n",
    "k개로 분할된 데이터를 교차해서 활용하는데, 방법은 다음과 같습니다. \n",
    "\n",
    "\n",
    "이처럼 k개로 나누어진 데이터를 k번 교차하여 학습하고 검증함으로써 모든 데이터를 학습에 사용할 수 있습니다. k-fold 교차 검증 방식은 모든 데이터를 평가와 학습에 사용할 수 있어 모델의 일반화된 성능을 정확하게 구할 수 있지만, 일반적인 분할 학습 방식에 비해 소요 시간이 늘어난다는 점을 유념하고 활용해야 합니다."
   ]
  },
  {
   "cell_type": "raw",
   "id": "a59c04b9-96a1-4e57-a457-1ec144082cec",
   "metadata": {},
   "source": [
    "#178"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db02fc4e-1bdc-487c-af03-69c1fa7c4937",
   "metadata": {},
   "source": [
    "## 3. 학습 과정을 시각화하여 과적합 확인하기\n",
    "AI 학습은 한 번만 수행하는 것이 아니라 학습과 검증을 반복하면서 성능을 향상합니다. 그 과정에서 전체 데이터를 학습 데이터(train data), 검증 데이터(validation)로 나누어서 학습과 검증에 활용합니다. <br>\n",
    "AI가 학습을 반복하는 과정에서 생성된 모델의 정확도와 오차를 학습 횟수에 따라 히스토리 형태로 기록하는데, 정확도를 높이고 오차를 줄이는 방향으로 학습을 진행하는 과정에서 문제가 발생할 수도 있습니다. <br>\n",
    "바로 과적합입니다. 과적합은 모델이 학습 데이터를 과하게 학습했다는 뜻입니다. 학습을 과하게 수행하면 학습 데이터에만 최적화된 모델이 되어서 `train` 정확도는 높아지지만 정작 실제 데이터에는 오차가 늘어나는 현상이 발생합니다. <br>\n",
    "과적합의 예시와 학습 과정 히스토리를 다음 그래프를 통해 살펴봅니다. <br>\n",
    "\n",
    "\n",
    "왼쪽 그래프를 보면 선을 중심으로 일반 모델과 과적합 모델이 정확히 구분되지만, 형태가 학습 데이터에만 최적화되어 있기 때문에 다른 실제 데이터가 들어왔을 때 오히려 잘못 판단하는 경우가 생길 수 있습니다. <br>\n",
    "학습 히스토리 그래프를 통해서도 과적합 여부를 확인할 수 있습니다. 가운데 그래프는 학습 횟수별 train과 validation의 오차를, 오른쪽 그래프는 학습 횟수별 train과 validation의 정확도를 나타낸 것입니다. <br>\n",
    "train 데이터를 보면 학습이 거듭됨에 따라 오차는 지속적으로 줄어들고 정확도는 올라가는 것을 볼 수 있습니다. 하지만 학습 과정에 포함되지 않은 validation 검증 과정의 오차를 보면 학습 횟수에 따라 오차가 감소하다가 다시 오차가 증가하는 구간이 있습니다. 그 구간이 과적합이 발생했을 것으로 우려되는 지점이며, 과적합 발생 직전의 모델이 가장 성능이 우수한 모델이라는 것을 알 수 있습니다. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b82f8d96-3c20-4751-bcbc-f037793a48a6",
   "metadata": {},
   "source": [
    "#179"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9091ac-5b18-46af-b9b1-b96818a46e30",
   "metadata": {},
   "source": [
    "# 5절. AI 모델 평가 이해하기\n",
    "앞서 데이터를 학습용과 검증용으로 분류하는 이유와 방법을 알아보았습니다. 검증용 데이터를 생성한 목적에 맞게, 모델의 성능이 적절히 평가되어야 성능 향상을 위한 작업들을 수행할 수 있습니다. AI 학습 모델을 평가하는 방법은 분류, 회귀에 따라 나눠집니다.\n",
    "\n",
    "## 1. 분류 모델 평가하기\n",
    "### 1) 오차 행렬\n",
    "분류 학습의 결과를 평가하는 데 가장 널리 쓰이는 지표입니다. 오차 행렬은 혼동 행렬이라고도 불리는데, 말 그대로 사용자가 혼동하기 쉬운 개념이니 잘 이해하는 것이 중요합니다. \n",
    "\n",
    "\n",
    "위 그림으로 평가지표에 대해 상세히 살펴봅니다. 먼저 주어진 데이터의 답(Label)이 `Positive`와 `Negative` 2가지로 분류된다고 가정합니다. 이를 학습한 AI 모델 또한 `Positive`와 `Negative`로 이진 분류를 수행합니다. 이 과정이 진행되었을 때 오차 행렬의 각 블록이 가지는 의미는 다음과 같습니다. \n",
    "- TP(True Positive) : 실제 답이 positive이고, 예측한 답도 positive로 정답\n",
    "- FP(False Positive) : 실제 답은 negative인데, 예측한 답이 positive로 오답\n",
    "- FN(False Positive) : 실제 답은 positive인데, 예측한 답이 negative로 오답\n",
    "- TN(True Negative) : 실제 답이 negative이고, 예측한 답도 negative로 정답"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9bf5e9d3-76f7-4ed8-b5b2-da54de9b7dff",
   "metadata": {},
   "source": [
    "#180"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ecd799-149f-427d-ae12-fc57e91e3085",
   "metadata": {},
   "source": [
    "이진 분류를 수행할 경우 위 4가지 외에 다른 경우의 수는 없으므로, TP+FP+FN+TN='전체 데이터의 수'라고 할 수 있습니다.\n",
    "오차 행렬에 쓰이는 평가지표의 의미는 다음과 같습니다.\n",
    "- Accuracy(정확도) : 전체 데이터 중  AI 모델이 예측하여 맞힌 비율\n",
    "- Recall(재현율) : 실제 positive 중  AI 모델이 Positgive예측하여 맞힌 비율\n",
    "- Precision(정밀도) : positive로 예측한 것 중 실제 positive인 비율\n",
    "- F1-score : Recall(재현율)과 Precision(정밀도)의 조화 평균\n",
    "\n",
    "다음 예시를 통해 더 자세히 알아봅니다. 검증 데이터가 총 100개이고, 그중 Positive=70, Negative=30  이라고 가정합니다. <br>\n",
    "[예시 1]처럼 AI 모델이 모든 Positive와 Negative를 정확히 예측한다면, 모든 지표가 1.00으로 계산됩니다. 하지만 실제로 대부분의 AI 모델은 아래와 같은 결과를 얻기 어렵습니다. \n",
    "\n",
    "\n",
    "[예시 2]는 AI 모델이 모두 Positive로 예측했을 경우입니다. Recall(재현율)만 보면 실제 70개의 positive를 모두 정확히 예측한 모델처럼 보이지만, Negative를 전혀 예측하지 못하기 때문에 좋은 모델이라고 보기 어렵습니다. \n",
    "\n",
    "\n",
    "[예시 3]은 AI 모델이 20개만 Positive로 예측한 경우입니다. Precision(정밀도)만 보면 positive를 잘 분류해낸 모델처럼 보이지만, 실제 positive 중 예측하지 못한 데이터가 더 많기 때문에 좋은 모델이라고 보기 어렵습니다. "
   ]
  },
  {
   "cell_type": "raw",
   "id": "df14c097-9ea1-42a8-9aa7-3dd9767f6104",
   "metadata": {},
   "source": [
    "#181"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c97a04-a619-4da9-b058-38ab68bc3b2f",
   "metadata": {},
   "source": [
    "위의 예시를 통해 어느 하나의 지표를 가지고 모델 성능을 평가하기는 어렵다는 것을 알 수 있습니다. 예측하고자 하는 데이터에 따라 재현율이 더 중요할 수도, 정밀도가 더 중요할 수도 있습니다. 다만 일반적인 상황에서 재현율과 정밀도는 한쪽이 높아지면 한쪽이 낮아지는 트레이드오프 관계일 수밖에 없기 때문에 2가지 지표를 모두 고려해야 합니다. 2가지 지표를 모두 고려한 것인 F1-score입니다. \n",
    "\n",
    "### 2) 정확도와 F1-score의 활용\n",
    "정확도와 F1-score은 데이터의 분포에 맞게 쓰임새가 다릅니다. 위의 예시처럼 7 : 3으로 균형 있게 나뉜 데이터는 정확도와 F1-score 모두 평가지표로 활용할 수 있습니다.<br> \n",
    "반면 다음과 같이 편중된 데이터를 살펴봅니다. 검증 데이터의 개수가 총 200개이고, A=170, B=10, C=10, D=10인 A라는 레이블로 편중된 데이터를 가정합니다. \n",
    "\n",
    "\n",
    "Model 1과 Model 2의 오차 행렬에서 정확도를 계산했을 때는 Model 1의 성능이 더 좋아 보입니다. 하지만 Model 1은 A레이블만 효과적으로 분류할 뿐 나머지 B, C, D를 분류해 내지는 못합니다. 반면 Model 2는 A레이블을 분류하는 기능은 Model 1보다 조금 떨어지지만, 나머지  B, C, D를 분류하는 측면에서는 더 뛰어난 모델입니다. "
   ]
  },
  {
   "cell_type": "raw",
   "id": "c8315cd0-936c-4fc9-b7c6-7b1ac45581f7",
   "metadata": {},
   "source": [
    "#182"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3995e534-2df0-4467-81bc-4c69b9c80730",
   "metadata": {},
   "source": [
    "따라서 정확도만 가지고 모델의 성능을 판단하기에는 데이터가 편중되었을 때 효과적이지 못한 것을 '정확도의 함정'이라고 합니다. 이러한 상황에서 활용되는 지표가 바로 F1-score입니다. \n",
    "\n",
    "\n",
    "위의 표는 Model 1과 Model 2의 F1-score를 비교한 것입니다. F1-score는 각 레이블당 재현율과 정밀도가 각각 계산되고 이를 활용한 종합적인 지표를 제공하기 때문에 Model 2의 점수가 Model 1보다 높게 계산되었습니다. <BR>\n",
    "이처럼 데이터가 편중되었을 때는 정확도 지표를 활용한 성능 평가보다 F1-score 지표를 활용한 성능 평가가 더 효과적입니다. \n",
    "\n",
    "### 3) ROC 곡선과 AUC\n",
    "분류 성능 평가지표 중 ROC 곡선과 AUC가 있습니다. ROC는 'Receiver Operation Curve'의 약자로 FPR(Fales Positive Rate)이 변함에 따른 TPR(True Positive Rate)의 변화를 그린 곡선을 의미합니다. <BR>\n",
    "FPR이란 FP/(TN+FP)로 실제 Negative 중 Positive라고 잘못 예측한 비율로 낮을수록 좋고, TPR이란 TP/(TP+FN)로 실제 Positive 중 Positive라고 잘 예측한 비율로 높을수록 좋습니다."
   ]
  },
  {
   "cell_type": "raw",
   "id": "a0817c34-6ca2-44d7-a913-b97e45ea6129",
   "metadata": {},
   "source": [
    "#183"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3706f252-0845-4c53-bafc-86ff1f215164",
   "metadata": {},
   "source": [
    "먼저 (1)번이 ROC 곡선과 (2)번 ROC 곡선을 비교했을 때, 곡선이 직각에 가까울수록 모델의 성능이 뛰어나다고 판단할 수 있습니다. 반대로 Random에 가까울수록 성능이 나쁘다고 판단할 수 있습니다. 여기서 Random은 무작위로 예측했을 때 나올 수 있는 최솟값을 선으로 나타낸 것입니다. <br>\n",
    "AUC는 'Area Under ROC'의 약자로, ROC 곡선 아래의 면적을 의미합니다. 마찬가지로 AUC 값이 클수록 모델의 성능이 좋다고 판단합니다. x축 y축의 최댓값이 각각 1이므로 최대 면적은 1이 되며, 최소 면적은 Random의 아래 면적인 0.5가 됩니다. \n",
    "\n",
    "## 2. 회귀 모델 평가하기\n",
    "회귀 모델에 대한 성능을 평가하는 지표를 알아봅니다. 회귀 모델은 예측값이 양적 데이터이므로 예측 결과를 '맞다', '틀리다'로 구분하기 어렵습니다. 또한 회귀 모델의 예측값이 실제 정답과 얼마나 차이 나는지도 고려해야 합니다. \n",
    "\n",
    "### 1) MAE\n",
    "MAE(Mean Absolute Error)는 '평균 절대 오차'로 산식은 다음과 같습니다.<BR>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ff42ce-387c-44c4-9581-c025bef0f5a6",
   "metadata": {},
   "source": [
    "$ \n",
    "\\text{MAE} = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i \n",
    "}\r\n",
    "$$\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8180599-4ae7-4388-8390-5320f271fb64",
   "metadata": {},
   "source": [
    "예측값에 대한 실제의 오차를 구하고, 그 절댓값의 평균을 구하는 것으로 모델의 성능을 평가하는 지표입니다. \n",
    "\n",
    "\n",
    "(1)번 모델이 예측한 값은 실제값과 오차가 적고, (2)번 모델이 예측한 값은 실제값과 오차가 큰 것을 알 수 있습니다. 따라서 오차가 작을수록 모델의 성능이 좋다고 판단할 수 있기 때문에, MAE의 값이 작은 모델을 찾아야 합니다. "
   ]
  },
  {
   "cell_type": "raw",
   "id": "03d3e44c-8cc2-4040-8ebf-920edee103e1",
   "metadata": {},
   "source": [
    "#184"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b132d475-79f1-4495-8227-c33944c7bc9d",
   "metadata": {},
   "source": [
    "### 2) MSE\n",
    "MSE(Mean Squared Error)는 '평균 제곱 오차'로 산식은 다음과 같습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce42cc40-c88b-4fb2-91a0-9a790175a8d7",
   "metadata": {},
   "source": [
    "$$\n",
    "MSE = \\frac{\\sum (y - \\hat{y})^2}{n}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c450b936-3d96-4eff-9dea-f2e0a4e3a0f6",
   "metadata": {},
   "source": [
    "예측값에 대한 실제값의 오차를 구하는 것은 MAE와 동일하지만 절댓값이 아닌 제곱을 취하고 그 값의 평균을 구하는 것으로 모델의 성능을 평가하는 지표입니다. <BR>\n",
    "절댓값을 취하는 것과 제곱을 취하는 것의 차이는 특이값(이상치)의 영향도를 파악하느 데에 있습니다. <BR>\n",
    "\n",
    "\n",
    "6번째 값이 오차가 작을 때 MAE와 MSE, 6번째 값이 기존에 비해 오차가 증가(특이값)했을 때 MAE와 MSE의 증감을 비교해 봅니다. <BR>\n",
    "MAE는 하나의 특이값이 발생하더라도 오차의 절댓값의 평균을 취하면서 영향도가 조금 줄어듭니다. 그러나 MSE는 하나의 특이값으로 인해 오차의 제곱의 평균을 취하면서 크게 영향을 미칩니다."
   ]
  },
  {
   "cell_type": "raw",
   "id": "016047ff-ae68-46f5-816f-201a4cb09670",
   "metadata": {},
   "source": [
    "#185<끝>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715cc283-32b6-4530-be45-7c62793dddd0",
   "metadata": {},
   "source": [
    "### 3) RMSE\n",
    "\n",
    "\n",
    "### 4) R2 Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4bebe5-9f2c-49fd-b6b5-0852a9490844",
   "metadata": {},
   "source": [
    "$ α^2 $"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
